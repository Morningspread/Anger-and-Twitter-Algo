{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Morningspread/Angry-Tweeter/blob/main/XGBoost_Twitter_Feb2%2C2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5863F8FwATMN"
      },
      "source": [
        "#Comparison of kNN, logistic regression & random forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsatNwc9L-MT"
      },
      "source": [
        "##Imports, display parameters and Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "AgCqWCA4ATMY"
      },
      "outputs": [],
      "source": [
        "#Sean's imports\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn \n",
        "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn import  metrics\n",
        "#print(\"scikit-learn version: %s\" %sklearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Riddhi's imports...\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"vader_lexicon\")\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOByYABPl2sa",
        "outputId": "35099185-e82e-4117-a973-ebfa56bbe763"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "tfMR1bo0ATMe"
      },
      "outputs": [],
      "source": [
        "#XG Boost now on both computers... \n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "aQlUg4flATMi"
      },
      "outputs": [],
      "source": [
        "# We want to max out the display here\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm9JdfdEA8VK",
        "outputId": "c5a6cfa1-5d71-47a3-9f25-258bae83c153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Mounting the drive... \n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvMVKbx-ATMj"
      },
      "source": [
        "### We need 4 metrics: accuracy, recall, precision and f1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "9d6Qh2HdATMl"
      },
      "outputs": [],
      "source": [
        "#Some code to compute metrics and display a table\n",
        "def mymetrics(pred,truth):\n",
        "    table = metrics.confusion_matrix(pred,truth)\n",
        "    tp = table[1,1]\n",
        "    tn = table[0,0]\n",
        "    fp = table[1,0]\n",
        "    fn = table[0,1]\n",
        "    \n",
        "    accuracy =(tp+tn)/pred.shape[0]\n",
        "    \n",
        "    if (tp + fn) == 0:\n",
        "        recall = 0.0\n",
        "    else:\n",
        "        recall = tp/(tp+fn)\n",
        "    if (tp + fp) == 0:\n",
        "        precision = 0.0\n",
        "    else:\n",
        "        precision = tp/(tp+fp)\n",
        "    if (recall+precision) == 0.0:\n",
        "        f1 = 0.0\n",
        "    else:\n",
        "        f1 = 2. * recall*precision/(recall+precision)\n",
        "    \n",
        "    ## Python code to print the data\n",
        "    a = tn\n",
        "    b = fn\n",
        "    c = a+b\n",
        "    e = fp\n",
        "    f = tp\n",
        "    g = e + f\n",
        "    #h = a + e\n",
        "    d = {\"Pred-0\": [a, b, c],\n",
        "    \"Pred-1\": [e, f, g] }\n",
        "    print (\"{:<8} {:<8} {:<20} {:<20}\".format(' ','True-0','True-1','rowsum'))\n",
        "    for k, v in d.items():\n",
        "        lang, perc, change = v\n",
        "        print (\"{:<8} {:<8} {:<20} {:<20}\".format(k, lang, perc, change))\n",
        "    print(\" \")\n",
        "    print(\"accuracy =\",(format (accuracy, '.2f')),\"   recall =\",(format (recall, '.2f')),\n",
        "    \"   precision =\",(format (precision, '.2f')),\"   f1_score =\",(format (f1, '.2f')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMAFFRgYATMq"
      },
      "source": [
        "## Read and pre-process data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "nWqyVhTGATMt"
      },
      "outputs": [],
      "source": [
        "#Checking the home directory \n",
        "\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "cwd\n",
        "\n",
        "#Changing the directory - for the Workstation \n",
        "os.chdir(r'/content/drive/MyDrive/Sean/Twitter/')\n",
        "\n",
        "#Google Drive/Analytics Rebirth/Projects/Despair/MLElect_Sept15.csv\n",
        "\n",
        "#Changing the directory for the X1 Yoga \n",
        "#os.chdir(r'C:\\\\Users\\\\Lenovo\\\\Google Drive\\\\Analytics Rebirth\\\\Despair')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "UmHVsOShATMw"
      },
      "outputs": [],
      "source": [
        "#importing the dataset - careful not to get the meta-million dataset\n",
        "# \n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Sean/Twitter/COVID_223KTweets.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "_pqCBcihhA78",
        "outputId": "e3e2eb6a-01fc-48de-8642-866e154a9684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(223955, 36)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    id      conversation_id               created_at        date      time  timezone              user_id         username                    name place                                              tweet language mentions                          urls                                             photos  replies_count  retweets_count  likes_count    hashtags cashtags                                               link  retweet quote_url  video                                        thumbnail  near  geo  source  user_rt_id  user_rt  retweet_id                                           reply_to  retweet_date  translate  trans_src  trans_dest\n",
              "0  1578109493392515073  1578109493392515073  2022-10-06 19:46:37 UTC  2022-10-06  19:46:37         0  1518980837135589376  krystynaklepin1            Christine K.   NaN  SAFE &amp; EFFECTIVE. Pfizer skipped major cat...       en       []                            []                                                 []              0               0            0          []       []  https://twitter.com/KrystynaKlepin1/status/157...    False       NaN      0                                              NaN   NaN  NaN     NaN         NaN      NaN         NaN                                                 []           NaN        NaN        NaN         NaN\n",
              "1  1578109461184454656  1578101418317082624  2022-10-06 19:46:30 UTC  2022-10-06  19:46:30         0  1497906018029907970  turdfur58439807          BlackSanta9111   NaN  @montanamike_tx @CastAwayOne1 Its a very small...       en       []                            []  ['https://pbs.twimg.com/media/FeaR-nlXEBsl6BB....              0               0            1          []       []  https://twitter.com/TurdFur58439807/status/157...    False       NaN      1  https://pbs.twimg.com/media/FeaR-nlXEBsl6BB.jpg   NaN  NaN     NaN         NaN      NaN         NaN  [{'screen_name': 'montanamike_tx', 'name': 'mi...           NaN        NaN        NaN         NaN\n",
              "2  1578109458038853637  1578109458038853637  2022-10-06 19:46:29 UTC  2022-10-06  19:46:29         0             36803382     yakimahealth  Yakima Health District   NaN  Escuela Secundaria West Valley Junior High lle...       es       []  ['http://YakimaVacunas.org']  ['https://pbs.twimg.com/media/FeaSMFDXEA8-GVj....              0               0            0          []       []  https://twitter.com/yakimahealth/status/157810...    False       NaN      1  https://pbs.twimg.com/media/FeaSMFDXEA8-GVj.jpg   NaN  NaN     NaN         NaN      NaN         NaN                                                 []           NaN        NaN        NaN         NaN\n",
              "3  1578109438464241666  1578087822858522630  2022-10-06 19:46:24 UTC  2022-10-06  19:46:24         0             16635842      spectrummag   SPECTRUM (Since 1969)   NaN  Lisa Beardsley-Hardy, GC director of education...       en       []                            []  ['https://pbs.twimg.com/media/FeaSGnfaYAAdYva....              0               0            0  ['gcac22']       []  https://twitter.com/spectrummag/status/1578109...    False       NaN      1  https://pbs.twimg.com/media/FeaSGnfaYAAdYva.jpg   NaN  NaN     NaN         NaN      NaN         NaN                                                 []           NaN        NaN        NaN         NaN\n",
              "4  1578109416825839616  1578107391580643329  2022-10-06 19:46:19 UTC  2022-10-06  19:46:19         0  1304242839228997632    yesbutcovid19          הטוויטז של גיא   NaN  @Techslut אה זה ננגד שפיכת זרע לבטלה? לא הבנתי...       iw       []                            []                                                 []              0               0            0          []       []  https://twitter.com/yesbutCOVID19/status/15781...    False       NaN      0                                              NaN   NaN  NaN     NaN         NaN      NaN         NaN  [{'screen_name': 'Techslut', 'name': 'Ilana Br...           NaN        NaN        NaN         NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ac64b38e-d8d8-4de2-986b-76f38ae8f210\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>date</th>\n",
              "      <th>time</th>\n",
              "      <th>timezone</th>\n",
              "      <th>user_id</th>\n",
              "      <th>username</th>\n",
              "      <th>name</th>\n",
              "      <th>place</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>mentions</th>\n",
              "      <th>urls</th>\n",
              "      <th>photos</th>\n",
              "      <th>replies_count</th>\n",
              "      <th>retweets_count</th>\n",
              "      <th>likes_count</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>cashtags</th>\n",
              "      <th>link</th>\n",
              "      <th>retweet</th>\n",
              "      <th>quote_url</th>\n",
              "      <th>video</th>\n",
              "      <th>thumbnail</th>\n",
              "      <th>near</th>\n",
              "      <th>geo</th>\n",
              "      <th>source</th>\n",
              "      <th>user_rt_id</th>\n",
              "      <th>user_rt</th>\n",
              "      <th>retweet_id</th>\n",
              "      <th>reply_to</th>\n",
              "      <th>retweet_date</th>\n",
              "      <th>translate</th>\n",
              "      <th>trans_src</th>\n",
              "      <th>trans_dest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1578109493392515073</td>\n",
              "      <td>1578109493392515073</td>\n",
              "      <td>2022-10-06 19:46:37 UTC</td>\n",
              "      <td>2022-10-06</td>\n",
              "      <td>19:46:37</td>\n",
              "      <td>0</td>\n",
              "      <td>1518980837135589376</td>\n",
              "      <td>krystynaklepin1</td>\n",
              "      <td>Christine K.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SAFE &amp;amp; EFFECTIVE. Pfizer skipped major cat...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://twitter.com/KrystynaKlepin1/status/157...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1578109461184454656</td>\n",
              "      <td>1578101418317082624</td>\n",
              "      <td>2022-10-06 19:46:30 UTC</td>\n",
              "      <td>2022-10-06</td>\n",
              "      <td>19:46:30</td>\n",
              "      <td>0</td>\n",
              "      <td>1497906018029907970</td>\n",
              "      <td>turdfur58439807</td>\n",
              "      <td>BlackSanta9111</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@montanamike_tx @CastAwayOne1 Its a very small...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://pbs.twimg.com/media/FeaR-nlXEBsl6BB....</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://twitter.com/TurdFur58439807/status/157...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>https://pbs.twimg.com/media/FeaR-nlXEBsl6BB.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'screen_name': 'montanamike_tx', 'name': 'mi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1578109458038853637</td>\n",
              "      <td>1578109458038853637</td>\n",
              "      <td>2022-10-06 19:46:29 UTC</td>\n",
              "      <td>2022-10-06</td>\n",
              "      <td>19:46:29</td>\n",
              "      <td>0</td>\n",
              "      <td>36803382</td>\n",
              "      <td>yakimahealth</td>\n",
              "      <td>Yakima Health District</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Escuela Secundaria West Valley Junior High lle...</td>\n",
              "      <td>es</td>\n",
              "      <td>[]</td>\n",
              "      <td>['http://YakimaVacunas.org']</td>\n",
              "      <td>['https://pbs.twimg.com/media/FeaSMFDXEA8-GVj....</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://twitter.com/yakimahealth/status/157810...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>https://pbs.twimg.com/media/FeaSMFDXEA8-GVj.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1578109438464241666</td>\n",
              "      <td>1578087822858522630</td>\n",
              "      <td>2022-10-06 19:46:24 UTC</td>\n",
              "      <td>2022-10-06</td>\n",
              "      <td>19:46:24</td>\n",
              "      <td>0</td>\n",
              "      <td>16635842</td>\n",
              "      <td>spectrummag</td>\n",
              "      <td>SPECTRUM (Since 1969)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Lisa Beardsley-Hardy, GC director of education...</td>\n",
              "      <td>en</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://pbs.twimg.com/media/FeaSGnfaYAAdYva....</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['gcac22']</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://twitter.com/spectrummag/status/1578109...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>https://pbs.twimg.com/media/FeaSGnfaYAAdYva.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1578109416825839616</td>\n",
              "      <td>1578107391580643329</td>\n",
              "      <td>2022-10-06 19:46:19 UTC</td>\n",
              "      <td>2022-10-06</td>\n",
              "      <td>19:46:19</td>\n",
              "      <td>0</td>\n",
              "      <td>1304242839228997632</td>\n",
              "      <td>yesbutcovid19</td>\n",
              "      <td>הטוויטז של גיא</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@Techslut אה זה ננגד שפיכת זרע לבטלה? לא הבנתי...</td>\n",
              "      <td>iw</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>https://twitter.com/yesbutCOVID19/status/15781...</td>\n",
              "      <td>False</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[{'screen_name': 'Techslut', 'name': 'Ilana Br...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ac64b38e-d8d8-4de2-986b-76f38ae8f210')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ac64b38e-d8d8-4de2-986b-76f38ae8f210 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ac64b38e-d8d8-4de2-986b-76f38ae8f210');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "#Let's look at the columns here...\n",
        "\n",
        "\n",
        "print(df.shape)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Filter only english tweets"
      ],
      "metadata": {
        "id": "Vn6iVHOfaGSo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Yh42ly7kATM6"
      },
      "outputs": [],
      "source": [
        "df=df[df['language']=='en']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP4Br0V2NVLn"
      },
      "source": [
        "##Creating hashtag and cashtag variable\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE6PEonA3DhP",
        "outputId": "b118298e-6a97-4218-d78c-683b6cf68eeb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]                                                                                                                                                                                                         75343\n",
              "['covid19']                                                                                                                                                                                                 5804\n",
              "['covid']                                                                                                                                                                                                    380\n",
              "['todaysmedicalupdate', 'medicine', 'health', 'patients', 'nhs', 'fmrevolution', 'today', 'insurance', 'pharmaceutical', 'biotech', 'covid19', 'coronavirus', 'doctor', 'policy', 'vaccine', 'medtech']      325\n",
              "['coronavirus', 'covid19']                                                                                                                                                                                   205\n",
              "                                                                                                                                                                                                           ...  \n",
              "['dr', 'us', 'covid19']                                                                                                                                                                                        1\n",
              "['palestine', 'israel', 'covid19', 'climatechange']                                                                                                                                                            1\n",
              "['covid19', 'covidisnotover', 'covid', 'covid19aus']                                                                                                                                                           1\n",
              "['idop2022', 'agingasia']                                                                                                                                                                                      1\n",
              "['news', 'btc', 'god', 'bb24', 'usa', 'nyc', 'bitcoin', 'covid19', 'russia', 'magat', 'gay', 'nftsales', 'metaverse', 'nuclear', 'audioleak', 'nato', 'ukrainewar']                                            1\n",
              "Name: hashtags, Length: 20097, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "#We need to create a hashtag variable...based on zero one...or the number of hashtags... \n",
        "\n",
        "df['hashtags'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create hashtag variable\n",
        "\n",
        "df['hash_count'] = df['hashtags'].str.split(\", \").str.len()"
      ],
      "metadata": {
        "id": "tNossSlOYS3j"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating cashtag variable \n",
        "\n",
        "df['cash_count'] = df['cashtags'].str.split(\", \").str.len()"
      ],
      "metadata": {
        "id": "YEfo7d3wYctp"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create @handle count\n"
      ],
      "metadata": {
        "id": "AZ9iWmi0iF19"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a function that counts the tweets..\n",
        "\n",
        "def count_handles(tweet):\n",
        "    return tweet.count(\"@\")\n",
        "\n",
        "    # add a new column to the dataframe with the handle count\n",
        "df[\"handle_count\"] = df[\"tweet\"].apply(count_handles)"
      ],
      "metadata": {
        "id": "WXF5eDZbjPMg"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the handle counts variable \n",
        "\n",
        "#df['handle_count'].value_counts()"
      ],
      "metadata": {
        "id": "M6XjLzvOjpLM"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Create sentiment index\n",
        "\n"
      ],
      "metadata": {
        "id": "oaJ8VJFmmGfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_relative_length(text, TWITTER_ALLOWED_CHARS=280.0):\n",
        "    \"\"\"\n",
        "    Returns the relative length of text.\n",
        "\n",
        "    Parameters:\n",
        "    ------\n",
        "    text: (str)\n",
        "    the input text\n",
        "\n",
        "    Keyword arguments:\n",
        "    ------\n",
        "    TWITTER_ALLOWED_CHARS: (float)\n",
        "    the denominator for finding relative length\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    relative length of text: (float)\n",
        "  \n",
        "    Normalizing the length of tweet\n",
        "    \"\"\"\n",
        "    return len(text) / TWITTER_ALLOWED_CHARS\n",
        "\n",
        "\n",
        "def get_length_in_words(text):\n",
        "    \"\"\"\n",
        "    Returns the length of the text in words.\n",
        "\n",
        "    Parameters:\n",
        "    ------\n",
        "    text: (str)\n",
        "    the input text\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    length of tokenized text: (int)\n",
        "\n",
        "    \"\"\"\n",
        "    return len(nltk.word_tokenize(text))\n",
        "\n",
        "\n",
        "def get_sentiment(text):\n",
        "    \"\"\"\n",
        "    Returns the compound score representing the sentiment: -1 (most extreme negative) and +1 (most extreme positive)\n",
        "    The compound score is a normalized score calculated by summing the valence scores of each word in the lexicon.\n",
        "\n",
        "    Parameters:\n",
        "    ------\n",
        "    text: (str)\n",
        "    the input text\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    sentiment of the text: (str)\n",
        "    \"\"\"\n",
        "    scores = sid.polarity_scores(text)\n",
        "    return scores[\"compound\"]"
      ],
      "metadata": {
        "id": "NefJxF4XmM4t"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLFgYqcFo97g",
        "outputId": "4e491ae4-7f5a-49ae-fe70-933eb9554020"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(116687, 39)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Assign the function to new variables... \n",
        "#We are only interested in Sentiment - as of Feb 1, 2023\n",
        "\n",
        "#df = df.assign(n_words=df[\"tweet\"].apply(get_length_in_words))\n",
        "df['sentiment'] = df.assign(vader_sentiment=df[\"tweet\"].apply(get_sentiment))\n",
        "#df = df.assign(rel_char_len=df[\"tweet\"].apply(get_relative_length))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "id": "_bl0tP0JmSC6",
        "outputId": "a3214716-761d-441a-b9db-a77c583df381"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sentiment'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3750\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3751\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3752\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sentiment'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-3647a61c4613>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df = df.assign(n_words=df[\"tweet\"].apply(get_length_in_words))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentiment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvader_sentiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_sentiment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#df = df.assign(rel_char_len=df[\"tweet\"].apply(get_relative_length))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3600\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3601\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3602\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_frame_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3603\u001b[0m         elif (\n\u001b[1;32m   3604\u001b[0m             \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_frame_value\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3740\u001b[0m         \u001b[0;31m# now align rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3741\u001b[0m         \u001b[0marraylike\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_reindex_for_setitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3742\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marraylike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3744\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iset_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mslice\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item_mgr\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3752\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3753\u001b[0m             \u001b[0;31m# This item wasn't present, just insert at end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3754\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3755\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3756\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iset_item_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value)\u001b[0m\n\u001b[1;32m   1160\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_block_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblkno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_fast_count_smallints\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblknos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mnew_block\u001b[0;34m(values, placement, ndim, klass)\u001b[0m\n\u001b[1;32m   1935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1936\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_pandas_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1937\u001b[0;31m     \u001b[0mcheck_ndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1939\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mklass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mcheck_ndim\u001b[0;34m(values, placement, ndim)\u001b[0m\n\u001b[1;32m   1977\u001b[0m             )\n\u001b[1;32m   1978\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1979\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   1980\u001b[0m                 \u001b[0;34mf\"Wrong number of items passed {len(values)}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m                 \u001b[0;34mf\"placement implies {len(placement)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Wrong number of items passed 40, placement implies 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk0iHqLjNZxU"
      },
      "source": [
        "##Create tweet length variable "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQaT6aS11TyC"
      },
      "outputs": [],
      "source": [
        "#We want to create the tweet length here...\n",
        "\n",
        "tweet = df['tweet']\n",
        "\n",
        "df['tweetlength'] = [len(t.split(' ')) for t in tweet]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcjP35H91rvJ"
      },
      "outputs": [],
      "source": [
        "#Let's plot the length in the tweets\n",
        "#Code syntax: hist = df.hist(bins=3)\n",
        "\n",
        "hist = df['tweetlength'].hist(bins=10)\n",
        "\n",
        "print(df['tweetlength'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image y/n and date/time variable "
      ],
      "metadata": {
        "id": "VPXHkDD_bMbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['image_len'] = df.photos.map(len)"
      ],
      "metadata": {
        "id": "3ZG4H6-TeKxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a y/n for images... \n",
        "\n",
        "df['imageyn']=np.where(df['image_len'] <= 0, 0,1)"
      ],
      "metadata": {
        "id": "OkXHrh4LbLGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d1i9AwMJoBV"
      },
      "outputs": [],
      "source": [
        "#But we might have to first get the object variables into datetime \n",
        "# Syntax:  pd.to_datetime(s, infer_datetime_format=True)\n",
        "\n",
        "df['date']= pd.to_datetime(df['date'],infer_datetime_format=True)\n",
        "df['time']= pd.to_datetime(df['time'],infer_datetime_format=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eTg0zTHISMO"
      },
      "outputs": [],
      "source": [
        "#Trying to convert the date into an integer... \n",
        "#Syntax:  test_df['Date'].dt.strftime(\"%Y%m%d\").astype(int)\n",
        "\n",
        "df['int_date'] = df['date'].dt.strftime(\"%Y%m%d\").astype(int)\n",
        "df['int_time'] = df['time'].dt.strftime(\"%H%M%S\").astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking the variable types... \n",
        "\n",
        "print(df['int_date'].dtype)\n",
        "print(df['int_time'].dtype)"
      ],
      "metadata": {
        "id": "8EdB574Wb84i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ew5E2EykN3pr"
      },
      "source": [
        "##Creating variable for unique_id \n",
        "\n",
        "Created with ChatGPT Feb 1,2023"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's check the shape of the dataset\n",
        "\n",
        "df.shape"
      ],
      "metadata": {
        "id": "1AFlG2cRliI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#How many unique user_ids do we have? \n",
        "#So we have about 50% of the dataset with non-unique IDs...\n",
        "#How would we get at the number of tweets...? What about a groupby dataset...\n",
        "\n",
        "df['user_id'].nunique()"
      ],
      "metadata": {
        "id": "sFmeSFeqXw7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLfY4SgJN5VV"
      },
      "outputs": [],
      "source": [
        "#Code source -> ChatGPT\n",
        "\n",
        "def create_row_column(df, col_name):\n",
        "  col = df[col_name]\n",
        "  row = []\n",
        "  for i in range(len(col)):\n",
        "    row.append(i)\n",
        "  df['new_user_id'] = pd.Series(row)\n",
        "  return df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function..\n",
        "\n",
        "df = create_row_column(df, 'user_id')"
      ],
      "metadata": {
        "id": "HbmACnindGzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['new_user_id'].isnull().sum()"
      ],
      "metadata": {
        "id": "xq-i1S6vlIry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tweet Rate - stuck on the interpretation \n",
        "  "
      ],
      "metadata": {
        "id": "KXqsyfAEg-7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the tweet rate\n",
        "\n",
        "from datetime import datetime\n",
        "then = pd.to_datetime(min(df['date']))\n",
        "now  = pd.to_datetime(max(df['date']))                        \n",
        "duration = now - then                        \n",
        "duration_in_seconds = duration.total_seconds()      \n",
        "duration_in_min=duration_in_seconds/60\n",
        "duration_in_min\n",
        "\n",
        "#Can this be applied back to the column? Not really...even though it's a vi\n",
        "\n",
        "#df['tweet_rate'] = duration_in_min\n"
      ],
      "metadata": {
        "id": "s_x-EsWKg-bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quw16B1fNgNs"
      },
      "source": [
        "##Define a new dataset - df shape (116687, 48)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "qt0iVl9zd3Du"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLcdudJYC1By"
      },
      "outputs": [],
      "source": [
        "#So we can use the above data to define our dataset...\n",
        "#Let's remove hte other engagement metrics for now - outcome below: \"retweets_count\",\"likes_count\"\n",
        "#Outcome variable: data['nreplies'] = np.where(data['replies_count'] >= 1, 0,1)\n",
        "#Let's remove the other Twitter engagement metrics as they are going to be correlated with the outcome: ,\"retweets_count\",\"likes_count\" \n",
        "\n",
        "data = pd.DataFrame(df, columns = [\"int_date\",\"int_time\",\"replies_count\",\"user_id\",\"sentiment\",\n",
        "                                   \"handle_count\",\"tweetlength\",\"hash_count\",\"cash_count\",\"imageyn\"])\n",
        "\n",
        "#Let's look at the table...\n",
        "\n",
        "data.head()\n",
        "\n",
        "#I want to print the shape and see how it compares to nunique\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dealing with missing data"
      ],
      "metadata": {
        "id": "Lur3YzWzXaDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking for missing data... \n",
        "\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "ig2nw-SnaTbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Looking at correlational structure"
      ],
      "metadata": {
        "id": "YFDnHH6AehAe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLnT7TKHATNE"
      },
      "outputs": [],
      "source": [
        "#Let's have an optional step of checking the correlations\n",
        "\n",
        "data.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g--pkHxtK80I"
      },
      "source": [
        "#Creating the target variable "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKZntgxI7clr"
      },
      "outputs": [],
      "source": [
        "#Dichotomizing a variable -> We are losing a lot of information here...but allows us to answer different questions... \n",
        "\n",
        "data['nreplies'] = np.where(data['replies_count'] >= 1, 0,1)\n",
        "\n",
        "data['nreplies'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0FwGo0m8Z_4"
      },
      "outputs": [],
      "source": [
        "#Dropping the data column...because it's gonna be the best predictor... \n",
        "\n",
        "data.drop(['replies_count'], axis = 1, inplace=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHoEKFDaATNC"
      },
      "outputs": [],
      "source": [
        "# Now let's try creating a target array... let's call it \"target\" - it HAS to be a categorical variable\n",
        "\n",
        "target = np.array(data.nreplies)\n",
        "\n",
        "#Split out the checking step from the creation set, because it gets dropped\n",
        "target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJG74o9oATNE"
      },
      "outputs": [],
      "source": [
        "#important STEP Drop the Target/Outcome Variable\n",
        "#The secondary variables that can also be dropped: 'year', 'totalvotes'\n",
        "\n",
        "data = data.drop(columns = ['nreplies'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwXf_utTATNH"
      },
      "source": [
        "# NOTE: I changed random_state to 0 to get more 1's in X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ySOQjAdNATNH"
      },
      "outputs": [],
      "source": [
        "#This won't split unless our arrays are aligned... \n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state = 0)\n",
        "\n",
        "#Now let's check these - ok, they seemed to be working...  \n",
        "X_train.shape\n",
        "#X_test?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_tL_3rWATNI"
      },
      "outputs": [],
      "source": [
        "#Testing out the size of the test dataset\n",
        "y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaP8mLqpATNK"
      },
      "source": [
        "Let's start by looking at an ideal machine learning tool and see what the metrics would be. We'll take the y_train and assume that is our prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2y2Q9BhATNL"
      },
      "outputs": [],
      "source": [
        "mymetrics(y_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYEsSoOBATNM"
      },
      "source": [
        "In the above table, we show true negative, false negative, false positive and true positive (with rowsum for each row).\n",
        "            tn     fn\n",
        "            fp     tp\n",
        "So ideally, we should get a table with 0 in the off-diagonal and non-zeros along the diagonal, and all metrics should be equal to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vczyTq7UATNM"
      },
      "source": [
        "## LOGISTIC REGRESSION - standardization of the data is required for this method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlM4IQZfATNN"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_std = scaler.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_M5rW0ATNO"
      },
      "source": [
        "We have to use class_weight = 'balanced' to account for imbalanced responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PYeg7xBATNP"
      },
      "outputs": [],
      "source": [
        "# Time to use some heavy artillery\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(C=1.0,class_weight='balanced',max_iter=300)\n",
        "\n",
        "logreg.fit(X_std, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FD5CihbUATNQ"
      },
      "outputs": [],
      "source": [
        "Y_pred = logreg.predict(X_std)\n",
        "print(\"TRAIN: Logistic Regression\")\n",
        "mymetrics(Y_pred,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDnF411aATNR"
      },
      "source": [
        "Note that accuracy has dropped but recall looks good. Our goal is to have a high accuracy and a high recall (so precision is going to take a hit). Try the test set but it needs to be standardized too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLRzoXs9ATNR"
      },
      "outputs": [],
      "source": [
        "Xt_std = scaler.fit_transform(X_test)\n",
        "\n",
        "Yt_pred = logreg.predict(Xt_std)\n",
        "print(\"TEST Logistic Regression\")\n",
        "mymetrics(Yt_pred,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7Oiama9ATNU"
      },
      "source": [
        "## RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZbXapc5SATNU"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#This is a tree-based method\n",
        "\n",
        "# train model with \"balanced\" setting to tell RandomForest that imbalance exists in data set\n",
        "k = 100\n",
        "rfc = RandomForestClassifier(n_estimators=k,max_depth=4,criterion='entropy',class_weight='balanced',random_state=11).fit(X_train, y_train)\n",
        "\n",
        "# predict on train set\n",
        "\n",
        "rfc_pred = rfc.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFhkIeUlATNV"
      },
      "outputs": [],
      "source": [
        "print(\"TRAIN: Random Forest n_estimators=100\")\n",
        "mymetrics(rfc_pred,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BZAdapyATNW"
      },
      "outputs": [],
      "source": [
        "rfc_predt = rfc.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG3yipdTATNW"
      },
      "outputs": [],
      "source": [
        "print(\"TEST: Random Forest n_estimators=100\")\n",
        "mymetrics(rfc_predt,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSCQtZPIATNY"
      },
      "source": [
        "## LAST STEP IS TO TRY MANY TRAIN/TEST SETS \n",
        "\n",
        "To validate that the results are repeatable. Use random_state to select different training/test sets below. Takes about 1 minute to run. Check plots and averages at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ku33QfHbATNY"
      },
      "outputs": [],
      "source": [
        "# Selecting good values for various parameters and trying different train/test sets\n",
        "rec = []\n",
        "pre = []\n",
        "acc = []\n",
        "f1 = []\n",
        "trec = []\n",
        "tpre = []\n",
        "tacc = []\n",
        "tf1 = []\n",
        "cm0 = []\n",
        "cm1 = []\n",
        "cm00 = []\n",
        "cm11 = []\n",
        "for k in range(100):                                                #loop on this    v   \n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, target, random_state = k)\n",
        "    #print(k)\n",
        "    rfc = RandomForestClassifier(n_estimators=100,max_depth=4,class_weight='balanced',random_state=11).fit(X_train, y_train)\n",
        "    \n",
        "    Y_pred = rfc.predict(X_train)\n",
        "    recall = metrics.recall_score(Y_pred,y_train)\n",
        "    precision = metrics.precision_score(Y_pred,y_train)\n",
        "    accuracy = metrics.accuracy_score(Y_pred,y_train)\n",
        "    f1_score = metrics.f1_score(Y_pred,y_train)\n",
        "    rec.append(recall)\n",
        "    pre.append(precision)\n",
        "    acc.append(accuracy)\n",
        "    f1.append(f1_score)\n",
        "    cmtr = metrics.confusion_matrix(Y_pred,y_train)\n",
        "    #cm0.append(cmtr[0,0]/(y_train.shape[0]-np.sum(y_train)))\n",
        "    #cm1.append(cmtr[1,1]/(np.sum(y_train)))\n",
        "    cm0.append(cmtr[1,1])\n",
        "    \n",
        "    rfc_predt = rfc.predict(X_test)\n",
        "    recall = metrics.recall_score(rfc_predt,y_test)\n",
        "    precision = metrics.precision_score(rfc_predt,y_test)\n",
        "    accuracy = metrics.accuracy_score(rfc_predt,y_test)\n",
        "    f1_score = metrics.f1_score(rfc_predt,y_test)\n",
        "    trec.append(recall)\n",
        "    tpre.append(precision)\n",
        "    tacc.append(accuracy)\n",
        "    tf1.append(f1_score)\n",
        "    cmts = metrics.confusion_matrix(rfc_predt,y_test)\n",
        "    #cm00.append(cmts[0,0]/(y_test.shape[0]-np.sum(y_test)))\n",
        "    #cm11.append(cmts[1,1]/(np.sum(y_test)))\n",
        "    cm00.append(cmts[1,1])\n",
        "    \n",
        "print(\"TRAINING SET metrics\")\n",
        "plt.plot(rec)\n",
        "plt.plot(pre)\n",
        "plt.plot(acc)\n",
        "plt.plot(f1)\n",
        "plt.show()\n",
        "print(\"TEST SET metrics\")\n",
        "plt.plot(trec)\n",
        "plt.plot(tpre)\n",
        "plt.plot(tacc)\n",
        "plt.plot(tf1)\n",
        "plt.show()\n",
        "#plt.plot(cm0)\n",
        "#plt.show()\n",
        "#plt.plot(cm1)\n",
        "#plt.plot(cm00)\n",
        "#plt.plot(cm11)\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bg7xjFTATNb"
      },
      "outputs": [],
      "source": [
        "#Accuracy\n",
        "np.mean(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hm6b8WHqATNc"
      },
      "outputs": [],
      "source": [
        "#Recall\n",
        "np.mean(tpre)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t2XCYpouATNc"
      },
      "outputs": [],
      "source": [
        "#Precision\n",
        "np.mean(trec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sqjESN4ATNd"
      },
      "outputs": [],
      "source": [
        "#F1 score\n",
        "np.mean(tf1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6B5Ze5PATNe"
      },
      "source": [
        "## Ensemble Method 1: Try bagging (i.e., averaging many runs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF_N8CYgATNf"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "X, y = make_classification(n_samples=100, n_features=4,\n",
        "                           n_informative=2, n_redundant=0,\n",
        "                           random_state=0, shuffle=False)\n",
        "rfc = RandomForestClassifier(n_estimators=100,max_depth=4,criterion='entropy',class_weight='balanced',random_state=11).fit(X_train, y_train)\n",
        "\n",
        "clf = BaggingClassifier(rfc,max_samples=1.0, max_features=1.0, bootstrap=False,\n",
        "                        n_estimators=100, random_state=0).fit(X_train, y_train)\n",
        "Yt_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Lc-BbrjATNf"
      },
      "outputs": [],
      "source": [
        "mymetrics(Yt_pred,y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LWWlqAqATNg"
      },
      "source": [
        "## Ensemble Method 2: Boosting using xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6fjzHMYATNg"
      },
      "outputs": [],
      "source": [
        "#So the clf classifier gets instantiated in this cell \n",
        "#When I -> \"ask it what is\" - clf? Says it's an XGB classifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "clf = XGBClassifier(\n",
        "        objective = 'binary:logistic', \n",
        "        booster = \"gbtree\",\n",
        "        eval_metric = 'auc', \n",
        "        nthread = 4,\n",
        "        eta = 0.1,\n",
        "        reg_lambda = 0.2,\n",
        "        gamma = 0.4,\n",
        "        max_depth = 5, \n",
        "        subsample = 0.5, \n",
        "        scale_pos_weight = 30.0, \n",
        "        colsample_bytree = 0.7, \n",
        "        colsample_bylevel = 0.7,\n",
        "        min_child_weight = 2,\n",
        "        alpha = 0,\n",
        "        random_state = 30, \n",
        "        nrounds = 200,\n",
        "        n_estimators=100\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5E8CDTJATNh"
      },
      "outputs": [],
      "source": [
        "clf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyNdZupqATNi"
      },
      "outputs": [],
      "source": [
        "Yt_pred = clf.predict(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8Nnh0jsATNi"
      },
      "outputs": [],
      "source": [
        "mymetrics(Yt_pred,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aChzz1dPATNj"
      },
      "outputs": [],
      "source": [
        "Yt_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AUgR7zOATNj"
      },
      "outputs": [],
      "source": [
        "mymetrics(Yt_pred,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vugU4eY1ATNl"
      },
      "outputs": [],
      "source": [
        "#Trying another method for XG Boost \n",
        "\n",
        "plot_importance(clf)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X29OXOtLATNl"
      },
      "outputs": [],
      "source": [
        "# Trying to get at feature importance \n",
        "print(clf.feature_importances_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bxTrGBRATNm"
      },
      "outputs": [],
      "source": [
        "#Plotting feature importance\n",
        "plt.bar(range(len(clf.feature_importances_)), clf.feature_importances_)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-22_AxIrATNm"
      },
      "outputs": [],
      "source": [
        "mymetrics(Y_pred,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vekShcphATNn"
      },
      "outputs": [],
      "source": [
        "#Trying to get at feature importance \n",
        "\n",
        "Yt_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9GG7iEeATNn"
      },
      "outputs": [],
      "source": [
        "mymetrics(Yt_pred,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OukUNtMeATNo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkU-f8JTATNo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "un4JoMDBATNo"
      },
      "outputs": [],
      "source": [
        "#Let's try another - simpler XG Boost model...\n",
        "\n",
        "model = XGBClassifier()\n",
        "model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsgKq3hvATNp"
      },
      "outputs": [],
      "source": [
        "mymetrics(Yt_pred,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMq0GVqRATNp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vreX7ex2ATNp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAdV8OSbATNq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}